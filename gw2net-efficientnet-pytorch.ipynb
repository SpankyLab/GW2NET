{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Many ideas were taken from the following notebooks:<br>\nhttps://www.kaggle.com/andradaolteanu/g2net-searching-the-sky-pytorch-effnet-w-meta<br>\nhttps://www.kaggle.com/yasufuminakama/g2net-efficientnet-b7-baseline-training/output?select=oof_df.csv<br>\nhttps://www.kaggle.com/yasufuminakama/g2net-efficientnet-b7-baseline-inference","metadata":{}},{"cell_type":"code","source":"!pip install -q nnAudio -qq\n!pip install -q efficientnet_pytorch -qq\n!pip install -q timm -qq\n\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\nimport os\nimport gc\nfrom tqdm.auto import tqdm\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport time\nimport random\nfrom random import shuffle\nimport math\nfrom scipy import signal\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib.pyplot import figure\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport cProfile, pstats\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-20T05:04:19.100419Z","iopub.execute_input":"2021-08-20T05:04:19.100785Z","iopub.status.idle":"2021-08-20T05:04:43.847707Z","shell.execute_reply.started":"2021-08-20T05:04:19.100712Z","shell.execute_reply":"2021-08-20T05:04:43.84679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\n# lr_scheduler provides methods to adjust the learning rate based on the number of epochs \n# https://pytorch.org/docs/stable/optim.html\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts\n\n# automatic mixed precision training\nfrom torch.cuda.amp import GradScaler #https://pytorch.org/docs/stable/amp.html#gradient-scaling\nfrom torch.cuda.amp import autocast #https://pytorch.org/docs/stable/amp.html#autocasting\n\n# albumentations to define transformation/augmentation for the train and validation datasets\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom efficientnet_pytorch import EfficientNet\nfrom nnAudio.Spectrogram import CQT1992v2\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\n\nimport timm","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:43.849317Z","iopub.execute_input":"2021-08-20T05:04:43.849657Z","iopub.status.idle":"2021-08-20T05:04:47.019774Z","shell.execute_reply.started":"2021-08-20T05:04:43.849616Z","shell.execute_reply":"2021-08-20T05:04:47.018736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAR:\n    use_timm = True\n    debug = False\n    if not use_timm:\n        model_name = 'efficientnet-b7'\n    else:\n        model_name = 'tf_efficientnet_b7_ns'\n    epochs = 3\n    down_sample = 10000\n    stack_images = True\n    target_col='target'\n    n_fold = 5\n    trn_folds = [0] # [0, 1, 2, 3, 4]\n    batch_size = 64\n    lr = 1e-4\n    min_lr = 1e-6\n    weight_decay = 0.000001\n    apex = False\n    num_workers = 4\n    gradient_accumulation_steps = 1\n    max_grad_norm = 1000\n    print_freq = 250\n    seed = 42\n    scheduler = 'CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n    factor = 0.2 # ReduceLROnPlateau\n    patience = 4 # ReduceLROnPlateau\n    eps = 1e-6 # ReduceLROnPlateau\n    T_max = 3 # CosineAnnealingLR\n    T_0 = 3 # CosineAnnealingWarmRestarts","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.021909Z","iopub.execute_input":"2021-08-20T05:04:47.02228Z","iopub.status.idle":"2021-08-20T05:04:47.03039Z","shell.execute_reply.started":"2021-08-20T05:04:47.022237Z","shell.execute_reply":"2021-08-20T05:04:47.028897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=19):\n    '''Sets the seed of the entire notebook so results are the same every time we run.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed()","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.032267Z","iopub.execute_input":"2021-08-20T05:04:47.032723Z","iopub.status.idle":"2021-08-20T05:04:47.050827Z","shell.execute_reply.started":"2021-08-20T05:04:47.032686Z","shell.execute_reply":"2021-08-20T05:04:47.049883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device available now:', device)","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.052328Z","iopub.execute_input":"2021-08-20T05:04:47.052997Z","iopub.status.idle":"2021-08-20T05:04:47.102228Z","shell.execute_reply.started":"2021-08-20T05:04:47.052858Z","shell.execute_reply":"2021-08-20T05:04:47.101299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.105906Z","iopub.execute_input":"2021-08-20T05:04:47.10618Z","iopub.status.idle":"2021-08-20T05:04:47.113209Z","shell.execute_reply.started":"2021-08-20T05:04:47.106153Z","shell.execute_reply":"2021-08-20T05:04:47.112209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.114529Z","iopub.execute_input":"2021-08-20T05:04:47.114923Z","iopub.status.idle":"2021-08-20T05:04:47.123823Z","shell.execute_reply.started":"2021-08-20T05:04:47.114883Z","shell.execute_reply":"2021-08-20T05:04:47.122949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.127202Z","iopub.execute_input":"2021-08-20T05:04:47.127636Z","iopub.status.idle":"2021-08-20T05:04:47.135335Z","shell.execute_reply.started":"2021-08-20T05:04:47.127603Z","shell.execute_reply":"2021-08-20T05:04:47.134362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_result(result_df: pd.DataFrame):\n    preds = result_df['preds'].values\n    labels = result_df[VAR.target_col].values\n    score = get_score(labels, preds)\n    print(f'Score: {score:<.4f}')","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.137813Z","iopub.execute_input":"2021-08-20T05:04:47.138257Z","iopub.status.idle":"2021-08-20T05:04:47.145382Z","shell.execute_reply.started":"2021-08-20T05:04:47.13822Z","shell.execute_reply":"2021-08-20T05:04:47.144508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def idx2path(idx: str, is_train: bool = True) -> str:\n    if is_train:\n        parent = '/kaggle/input/g2net-gravitational-wave-detection/train/'\n    else:\n        parent = '/kaggle/input/g2net-gravitational-wave-detection/test/'\n    return os.path.join(parent, idx[0], idx[1], idx[2], idx + '.npy')","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.147015Z","iopub.execute_input":"2021-08-20T05:04:47.14746Z","iopub.status.idle":"2021-08-20T05:04:47.155684Z","shell.execute_reply.started":"2021-08-20T05:04:47.147419Z","shell.execute_reply":"2021-08-20T05:04:47.154805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_training_info(epoch, step, train_loader, data_time, losses, start, grad_norm):\n    print('Epoch: [{0}][{1}/{2}] '\n          'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n          'Elapsed {remain:s} '\n          'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n          'Grad: {grad_norm:.4f}  '\n          .format(epoch+1, step, len(train_loader), data_time=data_time, loss=losses,\n                  remain=timeSince(start, float(step+1)/len(train_loader)), grad_norm=grad_norm))","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.156911Z","iopub.execute_input":"2021-08-20T05:04:47.157725Z","iopub.status.idle":"2021-08-20T05:04:47.170117Z","shell.execute_reply.started":"2021-08-20T05:04:47.157697Z","shell.execute_reply":"2021-08-20T05:04:47.169256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_validation_info(step, valid_loader, data_time, losses, start):\n    print('EVAL: [{0}/{1}] '\n          'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n          'Elapsed {remain:s} '\n          'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n          .format(step, len(valid_loader), data_time=data_time, loss=losses,\n                  remain=timeSince(start, float(step+1)/len(valid_loader))))","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.172307Z","iopub.execute_input":"2021-08-20T05:04:47.17259Z","iopub.status.idle":"2021-08-20T05:04:47.181041Z","shell.execute_reply.started":"2021-08-20T05:04:47.172563Z","shell.execute_reply":"2021-08-20T05:04:47.180034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.182403Z","iopub.execute_input":"2021-08-20T05:04:47.182893Z","iopub.status.idle":"2021-08-20T05:04:47.189465Z","shell.execute_reply.started":"2021-08-20T05:04:47.182821Z","shell.execute_reply":"2021-08-20T05:04:47.188504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Transforms or Augmentation using Albumentations\n#Â https://albumentations.ai/docs/examples/migrating_from_torchvision_to_albumentations/\n# ====================================================\ndef get_transforms(*, data: str):\n    if data == 'train':\n        return A.Compose([ToTensorV2(),])\n\n    elif data == 'valid':\n        return A.Compose([ToTensorV2(),])","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.19099Z","iopub.execute_input":"2021-08-20T05:04:47.19174Z","iopub.status.idle":"2021-08-20T05:04:47.199573Z","shell.execute_reply.started":"2021-08-20T05:04:47.191701Z","shell.execute_reply":"2021-08-20T05:04:47.19857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filterSig(waves, aHP, bHP):\n    '''Apply a 20Hz high pass filter to the three events'''\n    return np.array([signal.filtfilt(bHP, aHP, wave) for wave in waves]) #lfilter introduces a larger spike around 20hz","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.201343Z","iopub.execute_input":"2021-08-20T05:04:47.201833Z","iopub.status.idle":"2021-08-20T05:04:47.208451Z","shell.execute_reply.started":"2021-08-20T05:04:47.201795Z","shell.execute_reply":"2021-08-20T05:04:47.207539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, df, transform = None, prints = False, stack_images = True, test = False):\n        self.path = df['path'].values\n        self.target = df['target'].values\n        self.wave_transform = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=32, bins_per_octave=8)\n        self.transform = transform\n        self.test = test\n        self.prints = prints\n        self.stack_images = stack_images\n        #self.bHP, self.aHP = signal.butter(8, (20, 500), btype='bandpass', fs=2048)\n\n    def __len__(self):\n        return len(self.path)\n    \n    def __transform__(self, waves, wave_transform):\n        \n        '''Transforms the np_file into spectrogram.'''\n        #waves = filterSig(waves, aHP=self.aHP, bHP=self.bHP)\n        \n        if self.stack_images:\n            waves = np.hstack(waves)\n            waves = waves / np.max(waves)\n            waves = torch.from_numpy(waves).float()\n            image = wave_transform(waves)  \n        else:\n            image = []\n            for i in range(3):\n                wave = waves[i] / np.max(waves[i])\n                wave = torch.from_numpy(wave).float()\n                channel = wave_transform(wave).squeeze().numpy()\n                if self.transform:\n                    channel = self.transform(image=channel)['image'].squeeze().numpy()\n                image.append(channel)\n            image = torch.tensor(image).float() # Convert numpy array into torch object  \n        return image\n    \n    def __getitem__(self, idx):   \n        waves = np.load(self.path[idx])\n        image = self.__transform__(waves, self.wave_transform)\n        if self.stack_images and self.transform:\n            image = image.squeeze().numpy()\n            image = self.transform(image=image)['image']\n        if not self.test:\n            y = torch.tensor(self.target[idx], dtype=torch.float)\n            return image, y\n        else:\n            return image","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.209915Z","iopub.execute_input":"2021-08-20T05:04:47.210632Z","iopub.status.idle":"2021-08-20T05:04:47.225356Z","shell.execute_reply.started":"2021-08-20T05:04:47.210589Z","shell.execute_reply":"2021-08-20T05:04:47.224454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EffNet(nn.Module):\n    def __init__(self, var):\n        super().__init__()\n        self.var = var\n        self.channel = 1 if var.stack_images else 3\n        self.efficient_net = EfficientNet.from_pretrained(VAR.model_name, in_channels=self.channel) # output shape 1000 by default\n        self.classification = nn.Sequential(nn.Linear(1000, 1))\n        \n    def forward(self, x, prints=False):\n        x = self.efficient_net(x)\n        out = self.classification(x)\n        return out\n    \n\nclass EffNetTimm(nn.Module):\n    def __init__(self, var, pretrained=False):\n        super().__init__()\n        self.var = var\n        self.channel = 1 if var.stack_images else 3\n        self.model = timm.create_model(self.var.model_name, pretrained=pretrained, in_chans=self.channel)\n        self.n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(self.n_features, 1)\n\n    def forward(self, x):\n        out = self.model(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.2277Z","iopub.execute_input":"2021-08-20T05:04:47.228315Z","iopub.status.idle":"2021-08-20T05:04:47.239342Z","shell.execute_reply.started":"2021-08-20T05:04:47.228254Z","shell.execute_reply":"2021-08-20T05:04:47.238402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    '''\n    Function is called VAR.epochs number of times for a given (training folds)-(validation fold) combination.\n    '''\n    # store average over batches\n    #batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    \n    model.train() # switch to train mode\n    \n    start = end = time.time()\n    scaler = GradScaler() # for automatic mixed precision training\n    \n    # iterate through batches for a given fold\n    for step, (images, labels) in enumerate(train_loader): # train_loader loads data by batches\n        \n        data_time.update(time.time() - end) # measure batch data loading time\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        \n        if VAR.apex:\n            with autocast(): # for automatic mixed precision training\n                y_preds = model(images)\n                loss = criterion(y_preds.view(-1), labels)\n        else:\n            y_preds = model(images)\n            loss = criterion(y_preds.view(-1), labels)\n            \n        losses.update(loss.item(), batch_size) # record batch loss\n        \n        # accumulate loss over a given number of batches and then average\n        if VAR.gradient_accumulation_steps > 1:\n            loss = loss / VAR.gradient_accumulation_steps\n        \n        # backward() computes the gradient of current tensor w.r.t. graph leaves\n        # gradient (loss) gets accumulated until step() and zero_grad() are called! \n        if VAR.apex:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n        \n        # clips gradient norm of an iterable of parameters\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), VAR.max_grad_norm)\n        \n        # step() updates the parameters and zero_grad() sets the gradients to zero\n        if (step + 1) % VAR.gradient_accumulation_steps == 0:\n            if VAR.apex:\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                optimizer.step()\n                \n            for param in model.parameters():\n                param.grad = None\n        \n        #batch_time.update(time.time() - end) # measure elapsed time\n        end = time.time()\n        \n        if step % VAR.print_freq == 0 or step == (len(train_loader)-1):\n            print_training_info(epoch, step, train_loader, data_time, losses, start, grad_norm)\n            \n    return losses.avg","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.242687Z","iopub.execute_input":"2021-08-20T05:04:47.243164Z","iopub.status.idle":"2021-08-20T05:04:47.258898Z","shell.execute_reply.started":"2021-08-20T05:04:47.243126Z","shell.execute_reply":"2021-08-20T05:04:47.258022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_fn(valid_loader, model, criterion, device):\n    '''\n    Function is called VAR.epochs number of times for a given (training folds)-(validation fold) combination.\n    '''\n    #batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    \n    model.eval() # switch to evaluation mode\n    preds = []\n    start = time.time()\n    \n    for step, (images, labels) in enumerate(valid_loader):\n        data_time.update(time.time() - start) # measure data loading time\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        \n        # compute loss\n        with torch.no_grad(): # disable gradient calculation\n            y_preds = model(images)\n        loss = criterion(y_preds.view(-1), labels) #view(-1)?\n        losses.update(loss.item(), batch_size) # record loss\n        preds.append(y_preds.sigmoid().to('cpu').numpy()) # record accuracy\n        \n        if VAR.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        \n        #batch_time.update(time.time() - end) # measure elapsed time\n        end = time.time()\n        \n        if step % VAR.print_freq == 0 or step == (len(valid_loader)-1):\n            print_validation_info(step, valid_loader, data_time, losses, start)\n            \n    predictions = np.concatenate(preds)\n    return losses.avg, predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.260312Z","iopub.execute_input":"2021-08-20T05:04:47.260705Z","iopub.status.idle":"2021-08-20T05:04:47.272141Z","shell.execute_reply.started":"2021-08-20T05:04:47.260668Z","shell.execute_reply":"2021-08-20T05:04:47.270989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Train loop\n# ====================================================\ndef train_loop(model, folds: pd.DataFrame, fold: int) -> pd.DataFrame: #train_loop(train,0)\n    '''\n    Function is called once per a given (training folds)-(validation fold) combination: e.g. ([1,2,3,4])-([0]).\n    '''\n    print(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[VAR.target_col].values\n\n    train_dataset = Dataset(train_folds, transform=get_transforms(data='train'), \n                            stack_images=VAR.stack_images, test=False)\n    valid_dataset = Dataset(valid_folds, transform=get_transforms(data='train'), \n                            stack_images=VAR.stack_images, test=False)\n    \n    train_loader = DataLoader(train_dataset, batch_size=VAR.batch_size, shuffle=True, \n                              num_workers=VAR.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=VAR.batch_size * 2, shuffle=False, \n                              num_workers=VAR.num_workers, pin_memory=True, drop_last=False)\n    \n    # ====================================================\n    # scheduler \n    # ====================================================\n    def get_scheduler(optimizer):\n        if VAR.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=VAR.factor, patience=VAR.patience, verbose=True, eps=VAR.eps)\n        elif VAR.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=VAR.T_max, eta_min=VAR.min_lr, last_epoch=-1)\n        elif VAR.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=VAR.T_0, T_mult=1, eta_min=VAR.min_lr, last_epoch=-1)\n        return scheduler\n\n    # ====================================================\n    # optimizer / scheduler / criterion\n    # ====================================================\n    optimizer = Adam(model.parameters(), lr=VAR.lr, weight_decay=VAR.weight_decay, amsgrad=False)\n    scheduler = get_scheduler(optimizer)\n    criterion = nn.BCEWithLogitsLoss()\n    # ====================================================\n    # loop\n    # ====================================================\n    \n    best_score = 0.\n    best_loss = np.inf\n    \n    for epoch in range(VAR.epochs):\n        \n        start_time = time.time()\n        \n        # train\n        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n        \n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n        \n        # dynamic learning rate reduction based on some validation measurements\n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n            scheduler.step()\n\n        # scoring\n        score = get_score(valid_labels, preds)\n\n        elapsed = time.time() - start_time\n\n        print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        print(f'Epoch {epoch+1} - Score: {score:.4f}')\n\n        if score > best_score:\n            best_score = score\n            print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), 'preds': preds}, \n                       f'{VAR.model_name}_fold{fold}_best_score.pth')\n            \n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            print(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n            torch.save({'model': model.state_dict(), 'preds': preds},\n                        f'{VAR.model_name}_fold{fold}_best_loss.pth')\n    \n    valid_folds['preds'] = torch.load(f'{VAR.model_name}_fold{fold}_best_score.pth',\n                                      map_location=torch.device('cpu'))['preds']\n\n    return valid_folds","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.273657Z","iopub.execute_input":"2021-08-20T05:04:47.274077Z","iopub.status.idle":"2021-08-20T05:04:47.295658Z","shell.execute_reply.started":"2021-08-20T05:04:47.274001Z","shell.execute_reply":"2021-08-20T05:04:47.294768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference(model, test, states, device):\n    \n    test_dataset = Dataset(test, transform=get_transforms(data='valid'), stack_images=VAR.stack_images, \n                           test=True)\n    test_loader = DataLoader(test_dataset, batch_size=VAR.batch_size, shuffle=False, \n                             num_workers=VAR.num_workers, pin_memory=True)\n    \n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for state in states:\n            model.load_state_dict(state['model'])\n            model.eval()\n            with torch.no_grad():\n                y_preds = model(images)\n            avg_preds.append(y_preds.sigmoid().to('cpu').numpy())\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.297342Z","iopub.execute_input":"2021-08-20T05:04:47.298013Z","iopub.status.idle":"2021-08-20T05:04:47.307925Z","shell.execute_reply.started":"2021-08-20T05:04:47.297957Z","shell.execute_reply":"2021-08-20T05:04:47.306877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# main\n# ====================================================\ndef main():\n    \n    # ====================================================\n    # train\n    # ====================================================\n    train = pd.read_csv('/kaggle/input/g2net-gravitational-wave-detection/training_labels.csv')\n    train['path'] = train.apply(lambda x: idx2path(x['id']), axis=1)\n    \n    if VAR.debug:\n        VAR.epochs = 1\n        train = train.sample(n=VAR.down_sample, random_state=VAR.seed).reset_index(drop=True)\n    \n    Fold = StratifiedKFold(n_splits=VAR.n_fold, shuffle=True, random_state=VAR.seed)\n    \n    # Fold.split() produces 5 splits -> [1,2,3,4][5], [1,2,3,5][4], [1,2,4,5][3], [1,3,4,5][2], [2,3,4,5][1]\n    # Following loop assigns fold ID [1,2,3,4,5] to each sample\n    for n, (train_index, val_index) in enumerate(Fold.split(train, train[VAR.target_col])):\n        train.loc[val_index, 'fold'] = int(n)\n    train['fold'] = train['fold'].astype(int) # train (n_fold=5, trn_folds=[0])\n\n    # Model Instantiation\n    if not VAR.use_timm:\n        model = EffNet(VAR).to(device)\n    else:\n        model = EffNetTimm(VAR, pretrained=True).to(device)\n    \n    oof_df = pd.DataFrame() # will store \n    for fold in range(VAR.n_fold):\n        if fold in VAR.trn_folds:\n            _oof_df = train_loop(model, train, fold) # use the fold as the validation set\n            oof_df = pd.concat([oof_df, _oof_df]) # accumulate results over different val folds\n            print(f\"========== fold: {fold} result ==========\")\n            get_result(_oof_df) # get result of the val fold\n\n    # CV result\n    print(f\"========== CV ==========\")\n    get_result(oof_df) # get result of all the accumulated val folds\n    # save result\n    oof_df.to_csv('oof_df.csv', index=False)\n    \n    # ====================================================\n    # infer\n    # ====================================================\n    test = pd.read_csv('/kaggle/input/g2net-gravitational-wave-detection/sample_submission.csv')\n    test['path'] = test.apply(lambda x: idx2path(x['id'], is_train=False), axis=1)\n    if VAR.debug:\n        test = test.sample(n=VAR.down_sample, random_state=VAR.seed).reset_index(drop=True)\n    \n    states = [torch.load(f'{VAR.model_name}_fold{fold}_best_score.pth') for fold in VAR.trn_folds]        \n    predictions = inference(model, test, states, device)\n    test['target'] = predictions\n    test[['id', 'target']].to_csv('submission.csv', index=False)\n    \n    print(test.head())\n    print(test['target'].hist())","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.309867Z","iopub.execute_input":"2021-08-20T05:04:47.310144Z","iopub.status.idle":"2021-08-20T05:04:47.468248Z","shell.execute_reply.started":"2021-08-20T05:04:47.310108Z","shell.execute_reply":"2021-08-20T05:04:47.467194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"execution":{"iopub.status.busy":"2021-08-20T05:04:47.471998Z","iopub.execute_input":"2021-08-20T05:04:47.472594Z","iopub.status.idle":"2021-08-20T05:09:17.299851Z","shell.execute_reply.started":"2021-08-20T05:04:47.47255Z","shell.execute_reply":"2021-08-20T05:09:17.299051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"./submission.csv\"> Download File </a>","metadata":{}}]}